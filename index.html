<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Supplementary Materials - VIAS</title>
  <style>
    body {
      font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f9f9f9;
      color: #222;
      line-height: 1.6;
    }

    header {
      background-color: #003366;
      color: white;
      padding: 2rem 1rem;
      text-align: center;
    }

    header h1 {
      margin: 0;
      font-size: 2rem;
      font-weight: 600;
    }

    main {
      max-width: 900px;
      margin: 2rem auto;
      padding: 0 1rem;
      background-color: white;
      border-radius: 8px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }

    section {
      margin-bottom: 3rem;
    }

    section h2 {
      border-left: 4px solid #003366;
      padding-left: 10px;
      color: #003366;
      font-size: 1.4rem;
      margin-bottom: 0.5rem;
    }

    p {
      font-size: 1rem;
      text-align: justify;
    }

    iframe {
      display: block;
      margin: 1rem auto;
      max-width: 100%;
      border-radius: 8px;
      border: none;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 1rem;
      margin-bottom: 1rem;
      font-size: 0.95rem;
    }

    th, td {
      border: 1px solid #ddd;
      padding: 8px 10px;
      text-align: center;
    }

    th {
      background-color: #003366;
      color: white;
    }

    img {
      display: block;
      margin: 1rem auto;
      max-width: 100%;
      border-radius: 6px;
      border: 1px solid #ccc;
    }

    .caption {
      text-align: center;
      font-size: 0.9rem;
      color: #555;
      margin-top: -0.5rem;
      margin-bottom: 1.5rem;
    }

    /* 左右分栏布局 */
    .two-column-layout {
      display: flex;
      gap: 2rem;
      margin: 1.5rem 0;
    }

    .algorithm-column {
      flex: 1;
      min-width: 0;
    }

    .explanation-column {
      flex: 1;
      min-width: 0;
    }

    /* 伪代码样式 - 与图片完全一致 */
    .algorithm-container {
      background-color: white;
      border: 1px solid #ddd;
      border-radius: 4px;
      padding: 20px;
      font-family: 'Times New Roman', serif;
      font-size: 10.5pt;
      line-height: 1.3;
      height: fit-content;
    }

    .algorithm-title {
      text-align: center;
      font-weight: bold;
      font-size: 11pt;
      margin-bottom: 15px;
    }

    .algorithm-line {
      margin: 4px 0;
      font-family: 'Courier New', monospace;
    }

    .algorithm-keyword {
      font-weight: bold;
    }

    .algorithm-comment {
      color: #666;
      font-style: italic;
    }

    .algorithm-label {
      font-weight: bold;
    }

    .indent-1 { margin-left: 20px; }
    .indent-2 { margin-left: 40px; }
    .indent-3 { margin-left: 60px; }

    .algorithm-require {
      margin-bottom: 10px;
    }

    /* 解释部分样式 */
    .explanation-content {
      background-color: #f8f9fa;
      border-left: 4px solid #003366;
      padding: 20px;
      border-radius: 0 8px 8px 0;
    }

    .explanation-content h3 {
      color: #003366;
      margin-top: 0;
      margin-bottom: 1rem;
    }

    .explanation-point {
      margin-bottom: 1rem;
      padding-left: 1rem;
      border-left: 2px solid #3498db;
    }

    .explanation-point strong {
      color: #2c3e50;
    }

    footer {
      background-color: #003366;
      color: white;
      text-align: center;
      padding: 1rem;
      font-size: 0.85rem;
    }

    /* 响应式设计 */
    @media (max-width: 768px) {
      .two-column-layout {
        flex-direction: column;
        gap: 1rem;
      }
      
      .algorithm-column,
      .explanation-column {
        width: 100%;
      }
      
      header h1 {
        font-size: 1.5rem;
      }
      
      section h2 {
        font-size: 1.2rem;
      }
      
      .algorithm-container {
        padding: 15px;
        font-size: 10pt;
      }
    }
  </style>
</head>

<body>
  <header>
    <h1>Initializing and Shaping Robot Policies with Language-based Value Estimation</h1>
    <h2>Appendix</h2>
  </header>

  <main>

    <!-- Abstract -->
    <section>
      <h2>Abstract</h2>
      <p>
        Reinforcement Learning (RL) enables robots to learn complex tasks, but suffers from poor sample efficiency, especially in environments where language is used to describe goals and actions. While recent work has explored the integration of RL with large language models (LLMs), most methods focus on policy learning and overlook the potential of using the knowledge as structured feedback to guide value estimation. We present Value Initialization and Adaptive Shaping (VIAS), a framework that uses large language models as external critics to provide linguistic guidance for value estimation. VIAS enhances sample efficiency by using language for both informed initialization and value shaping during training. Evaluated on two robots and in VirtualHome environment, VIAS outperforms standard RL baselines in both learning speed and task completion, demonstrating its potential for real-world robot applications.
      </p>
    </section>

    <!-- Video -->
    <section>
      <h2>Video Demonstration of Real Robots Experiments with VIAS</h2>
      <iframe width="720" height="405" src="https://www.youtube.com/embed/l7xpJGB_HDQ" allowfullscreen></iframe>
      <p class="caption">Video 1. Demonstration of VIAS performance in robot experiments.</p>
      <p>
        This video demonstrates the learning process and task completion results of the VIAS framework.To validate the proposed approach in a real-world scenario, we conducted a real-robot experiment using a mobile manipulator tasked with setting up a table according to a specified goal. The mobile manipulator used in this demonstration consists of a Segway base for navigation, a UR5e robotic arm equipped with a Hand-E gripper mounted on the Segway base for manipulation, and an overhead RGB-D camera fixed relative to the robot for perception. This setup provides the robot with the capabilities to perceive its environment, navigate within it, and interact with objects effectively.
      </p>
    </section>

    <!-- 其他部分保持不变 -->
    <!-- Images -->
    <section>
      <h2>Figures and Explanations</h2>
      <img src="algo.png" alt="VIAS Framework Overview" />
      <p class="caption">Figure 1. Overview of the VIAS framework combining RL and LLM-based value shaping.</p>
    </section>

    <section>
      <h2>Figures and Explanations</h2>
      <img src="para.png" alt="Parameter Analysis" />
      <p class="caption">Figure 2. Parameter analysis and sensitivity studies.</p>
    </section>

    <section>
      <h2>Figures and Explanations</h2>
      <img src="3d.png" alt="3D Visualization" />
      <p class="caption">Figure 3. 3D visualization of the value shaping process.</p>
    </section>

    <!-- Q-Value Evaluation Prompt -->
    <section>
      <h2>Q-Value Evaluation Prompt</h2>
      <div style="
        border: 1px solid #ccc; 
        background-color: #f9f9f9; 
        padding: 16px; 
        border-radius: 6px; 
        font-family: 'Courier New', monospace; 
        white-space: pre-wrap;
        line-height: 1.5;
        overflow-x: auto;
      ">
    <b>Q-Value Evaluation Prompt</b>
    "Your task is to estimate Q-values. Given a list of different observations and corresponding possible actions, please evaluate the Q-value of each action. The Q-value represents the expected cumulative reward obtained by taking that action in the current state and following the optimal policy thereafter. Please return a numeric score between 0.0 and 1.0 for each action, where:
    - 1.0 indicates the highest possible expected utility toward achieving the goal.
    - 0.0 indicates no expected utility or a clearly wrong move.
    Return the values in dictionary format. Only return numeric values between 0.0 and 1.0. If an action appears nonsensical, assign it 0.0.
    
    You may use commonsense spatial reasoning. If a goal involves placing an object on a specific surface, you can infer which intermediate steps (e.g., walking to, grabbing) are needed to accomplish the goal. An object must be near you to grab it. You must be holding an object to put it back on another surface.
    
    [VALID ACTIONS]
    - walk cutleryfork
    - walk wineglass
    - walk plate
    - walk kitchentable
    - walk kitchencounter
    - walk kitchen
    - walk bathroom
    - walk bedroom
    - walk livingroom
    - grab cutleryfork
    - grab wineglass
    - grab plate
    - putback cutleryfork kitchencounter
    - putback wineglass kitchencounter
    - putback plate kitchencounter
    - putback cutleryfork kitchentable
    - putback wineglass kitchentable
    - putback plate kitchentable
    
    {EXAMPLES}
    Now generate Q values:
    {OBSERVATION TEMPLATE}
    Q values:"
    
    <b>Observation Template</b>
    "[OBSERVATION]
Goal: put 1 {obj1} on {surface}, put 1 {obj1} on {surface}.
You are in {room}.
You see {reachable objects}.
You are close to {reachable objects}.
You are holding {grabable objects}.
{grabable object} is on the {surface}.
Previous Action: {action}"
    
    <b>Q-Value Evaluation Prompt</b>
    "{
"walk cutleryfork": 0.2,
"walk wineglass": 0.2,
"walk plate": 0.0,
"walk kitchentable": 0.8,
"walk kitchencounter": 0.1,
"walk kitchen": 0.0,
"walk bathroom": 0.0,
"walk bedroom": 0.0,
"walk livingroom": 0.0,
"grab cutleryfork": 1.0,
"grab wineglass": 1.0,
"grab plate": 0.0,
"putback cutleryfork kitchencounter": 0.0,
"putback wineglass kitchencounter": 0.0,
"putback plate kitchencounter": 0.0,
"putback cutleryfork kitchentable": 0.0,
"putback wineglass kitchentable": 0.0,
"putback plate kitchentable": 0.0
}"
      </div>
    </section>

    <!-- Prompt Examples -->
    <section>
      <h2>Prompt Examples and Explanation</h2>
      <pre style="background:#f3f3f3; padding:1rem; border-radius:8px; overflow-x:auto; white-space: pre-wrap;">
    <b>Prompt:</b> "Given the current state and goal, <strong>Your task is to estimate Q-values</strong> for action 'move block to table'."
    <b>Response:</b> "Based on prior tasks, moving the block is a high-value action when goal proximity &gt; 0.8. Estimated Q-value ≈ 0.92."
      </pre>
      <p class="caption">Example of linguistic Q-value estimation prompt used in VIAS.</p>
      <p>
        Prompts are designed to encourage the LLM to provide structured value judgments rather than raw textual outputs.
        These linguistic Q-values are then integrated into the RL training loop for adaptive value shaping.
      </p>
    </section>
  </main>

  <footer>
    &copy; 2025 VIAS Research Team — Supplementary Materials for ICRA Submission
  </footer>
</body>
</html>
